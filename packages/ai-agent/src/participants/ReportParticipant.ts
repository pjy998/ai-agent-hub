import * as vscode from 'vscode';
import { SelfProjectScanAgent } from '../agents/SelfProjectScanAgent';
import { CSharpAnalysisCommand } from '../commands/csharp-analysis';
import { LLMMonitor } from '../monitoring/llm-monitor';
import { PerformanceMonitor } from '../config/optimization-config';
import { IntelligentParticipant, ExecutionFlow } from './base/intelligent-participant';
import { UserIntentAnalysis } from '../services/intelligent-input-analyzer';

/**
 * é¡¹ç›®æŠ¥å‘Šç”Ÿæˆ Chat å‚ä¸è€…
 * ä½¿ç”¨GPT-4.1æ™ºèƒ½åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæä¾›å„ç§æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
 */
export class ReportParticipant extends IntelligentParticipant {
  private selfAnalysisAgent: SelfProjectScanAgent;
  private csharpAnalysisCommand: CSharpAnalysisCommand;
  private llmMonitor: LLMMonitor;

  constructor() {
    super('report');
    this.selfAnalysisAgent = new SelfProjectScanAgent();
    this.csharpAnalysisCommand = new CSharpAnalysisCommand();
    this.llmMonitor = LLMMonitor.getInstance();
    this.initializeFlows();
  }

  /**
   * åˆå§‹åŒ–æ‰§è¡Œæµç¨‹
   */
  protected initializeFlows(): void {
    this.registerFlow({
      name: 'project_report',
      description: 'ç”Ÿæˆå®Œæ•´çš„é¡¹ç›®åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ä»£ç è´¨é‡ã€æ¶æ„åˆ†æç­‰',
      supportedIntents: ['project_analysis', 'code_analysis', 'quality_check'],
      execute: async (
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken,
        analysis: UserIntentAnalysis
      ) => {
        await this.executeProjectReportRequest(request.prompt, stream, token, analysis);
      },
    });

    this.registerFlow({
      name: 'csharp_report',
      description: 'ä¸“é—¨é’ˆå¯¹C#é¡¹ç›®çš„ä»£ç åˆ†æå’Œè§„èŒƒæ£€æŸ¥æŠ¥å‘Š',
      supportedIntents: ['csharp_analysis', 'code_standards', 'quality_check'],
      execute: async (
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken,
        analysis: UserIntentAnalysis
      ) => {
        await this.executeCSharpReportRequest(stream, token);
      },
    });

    this.registerFlow({
      name: 'llm_report',
      description: 'ç”ŸæˆAIæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡å’Œæ€§èƒ½åˆ†ææŠ¥å‘Š',
      supportedIntents: ['llm_monitoring', 'usage_statistics', 'performance_analysis'],
      execute: async (
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken,
        analysis: UserIntentAnalysis
      ) => {
        await this.executeLLMReportRequest(request.prompt, stream);
      },
    });

    this.registerFlow({
      name: 'performance_report',
      description: 'ç”Ÿæˆé¡¹ç›®æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–å»ºè®®æŠ¥å‘Š',
      supportedIntents: ['performance_analysis', 'optimization', 'monitoring'],
      execute: async (
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken,
        analysis: UserIntentAnalysis
      ) => {
        await this.executePerformanceReportRequest(stream);
      },
    });

    this.registerFlow({
      name: 'help',
      description: 'æ˜¾ç¤ºæŠ¥å‘Šå‚ä¸è€…çš„ä½¿ç”¨å¸®åŠ©',
      supportedIntents: ['help', 'usage', 'guide'],
      execute: async (
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken,
        analysis: UserIntentAnalysis
      ) => {
        await this.executeHelpRequest(stream);
      },
    });

    this.setDefaultFlow('help');
  }

  /**
   * æ£€æŸ¥å·¥ä½œåŒºæ˜¯å¦å¯ç”¨
   */
  private checkWorkspace(stream: vscode.ChatResponseStream): boolean {
    if (!vscode.workspace.workspaceFolders || vscode.workspace.workspaceFolders.length === 0) {
      stream.markdown('âŒ **é”™è¯¯**: è¯·å…ˆæ‰“å¼€ä¸€ä¸ªå·¥ä½œåŒºæ‰èƒ½ç”ŸæˆæŠ¥å‘Šã€‚');
      return false;
    }
    return true;
  }

  /**
   * æ‰§è¡Œé¡¹ç›®æŠ¥å‘Šè¯·æ±‚
   */
  private async executeProjectReportRequest(
    prompt: string,
    stream: vscode.ChatResponseStream,
    token: vscode.CancellationToken,
    analysis: UserIntentAnalysis
  ): Promise<void> {
    stream.markdown('ğŸ” **å¼€å§‹é¡¹ç›®åˆ†æ**\n\næ­£åœ¨æ‰«æé¡¹ç›®ç»“æ„å’Œä»£ç è´¨é‡...');

    try {
      // æ‰§è¡Œé¡¹ç›®åˆ†æ
      const analysis = await this.selfAnalysisAgent.scanProject();
      const report = await this.selfAnalysisAgent.generateReport(analysis);

      // è§£ææŠ¥å‘Šæ ¼å¼åå¥½
      const format = this.extractFormatFromPrompt(prompt);

      stream.markdown('\n\nâœ… **åˆ†æå®Œæˆï¼**\n\n');

      // æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
      stream.markdown('## ğŸ“Š æŠ¥å‘Šæ‘˜è¦\n\n');
      stream.markdown(`- **é¡¹ç›®åç§°**: ${report.summary.projectName}\n`);
      stream.markdown(`- **åˆ†ææ—¥æœŸ**: ${report.summary.analysisDate}\n`);
      stream.markdown(`- **æ•´ä½“å¥åº·åº¦**: ${report.summary.overallHealth}/100\n`);
      stream.markdown(`- **å…³é”®é—®é¢˜**: ${report.summary.criticalIssues} ä¸ª\n`);
      stream.markdown(`- **æ”¹è¿›å»ºè®®**: ${report.summary.recommendations} æ¡\n\n`);

      // ä¿å­˜å®Œæ•´æŠ¥å‘Š
      const reportPath = await this.selfAnalysisAgent.saveReport(report, format);
      stream.markdown(`ğŸ“„ **å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜**: \`${reportPath}\`\n\n`);

      // æ˜¾ç¤ºå…³é”®å‘ç°
      if (report.summary.criticalIssues > 0) {
        stream.markdown('âš ï¸ **å…³é”®é—®é¢˜æ¦‚è§ˆ**:\n\n');
        const criticalIssues = analysis.recommendations
          .filter(r => r.priority === 'high')
          .slice(0, 3);

        criticalIssues.forEach((issue, index) => {
          stream.markdown(`${index + 1}. **${issue.title}**\n`);
          stream.markdown(`   ${issue.description}\n\n`);
        });
      }

      stream.markdown('ğŸ’¡ **æç¤º**: ä½¿ç”¨ `@report å¸®åŠ©` æŸ¥çœ‹æ›´å¤šæŠ¥å‘Šç±»å‹');
    } catch (error) {
      stream.markdown(
        `âŒ **é¡¹ç›®åˆ†æå¤±è´¥**: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }

  /**
   * æ‰§è¡ŒC#æŠ¥å‘Šè¯·æ±‚
   */
  private async executeCSharpReportRequest(
    stream: vscode.ChatResponseStream,
    token: vscode.CancellationToken
  ): Promise<void> {
    stream.markdown('ğŸ” **å¼€å§‹C#é¡¹ç›®åˆ†æ**\n\næ­£åœ¨åˆ†æC#ä»£ç è´¨é‡å’Œç»“æ„...');

    try {
      await this.csharpAnalysisCommand.generateProjectReport();
      stream.markdown('\n\nâœ… **C#é¡¹ç›®æŠ¥å‘Šå·²ç”Ÿæˆï¼**\n\n');
      stream.markdown('ğŸ“„ æŠ¥å‘Šå·²åœ¨æ–°çš„ç¼–è¾‘å™¨æ ‡ç­¾é¡µä¸­æ‰“å¼€ï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š\n\n');
      stream.markdown('- ğŸ“Š é¡¹ç›®æ¦‚è§ˆå’Œç»Ÿè®¡ä¿¡æ¯\n');
      stream.markdown('- ğŸ—ï¸ ä»£ç ç»“æ„åˆ†æ\n');
      stream.markdown('- ğŸ“ˆ å¤æ‚åº¦å’Œè´¨é‡æŒ‡æ ‡\n');
      stream.markdown('- âš ï¸ è´¨é‡é—®é¢˜å’Œæ”¹è¿›å»ºè®®\n');
      stream.markdown('- ğŸ“¦ ä¾èµ–å…³ç³»åˆ†æ\n\n');
    } catch (error) {
      stream.markdown(
        `âŒ **C#åˆ†æå¤±è´¥**: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }

  /**
   * æ‰§è¡ŒLLMä½¿ç”¨æŠ¥å‘Šè¯·æ±‚
   */
  private async executeLLMReportRequest(
    prompt: string,
    stream: vscode.ChatResponseStream
  ): Promise<void> {
    stream.markdown('ğŸ“Š **LLMä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š**\n\n');

    // è§£ææ—¶é—´èŒƒå›´
    const timeRange = this.extractTimeRangeFromPrompt(prompt);

    try {
      const report = this.llmMonitor.generateReport(timeRange);
      stream.markdown(report);

      stream.markdown('\n\nğŸ’¡ **æç¤º**: \n');
      stream.markdown('- ä½¿ç”¨ `@report llm 7å¤©` æŸ¥çœ‹ä¸€å‘¨ç»Ÿè®¡\n');
      stream.markdown('- ä½¿ç”¨ `@report llm 1å°æ—¶` æŸ¥çœ‹æœ€è¿‘ä¸€å°æ—¶\n');
    } catch (error) {
      stream.markdown(
        `âŒ **LLMæŠ¥å‘Šç”Ÿæˆå¤±è´¥**: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }

  /**
   * æ‰§è¡Œæ€§èƒ½æŠ¥å‘Šè¯·æ±‚
   */
  private async executePerformanceReportRequest(stream: vscode.ChatResponseStream): Promise<void> {
    stream.markdown('âš¡ **æ€§èƒ½ç›‘æ§æŠ¥å‘Š**\n\n');

    try {
      // åˆ›å»ºæ€§èƒ½ç›‘æ§å®ä¾‹å¹¶ç”ŸæˆæŠ¥å‘Š
      const monitor = new PerformanceMonitor();
      const report = monitor.generateReport();

      if (report.trim()) {
        stream.markdown(report);
      } else {
        stream.markdown('ğŸ“ **å½“å‰æ²¡æœ‰æ€§èƒ½ç›‘æ§æ•°æ®**\n\n');
        stream.markdown('æ€§èƒ½ç›‘æ§ä¼šåœ¨ä»¥ä¸‹æƒ…å†µä¸‹æ”¶é›†æ•°æ®ï¼š\n');
        stream.markdown('- é¡¹ç›®åˆ†æè¿‡ç¨‹ä¸­\n');
        stream.markdown('- Token Probeæµ‹è¯•æœŸé—´\n');
        stream.markdown('- å¤§å‹æ“ä½œæ‰§è¡Œæ—¶\n\n');
        stream.markdown('ğŸ’¡ **å»ºè®®**: å…ˆæ‰§è¡Œä¸€äº›åˆ†ææ“ä½œï¼Œç„¶åå†æŸ¥çœ‹æ€§èƒ½æŠ¥å‘Šã€‚');
      }
    } catch (error) {
      stream.markdown(
        `âŒ **æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå¤±è´¥**: ${error instanceof Error ? error.message : String(error)}`
      );
    }
  }

  /**
   * æ‰§è¡Œå¸®åŠ©è¯·æ±‚
   */
  private async executeHelpRequest(stream: vscode.ChatResponseStream): Promise<void> {
    const helpMessage = this.generateHelpMessage();
    stream.markdown(helpMessage);
  }

  /**
   * æ‰§è¡Œé»˜è®¤è¯·æ±‚
   */
  private async executeDefaultRequest(stream: vscode.ChatResponseStream): Promise<void> {
    stream.markdown('ğŸ‘‹ **æ¬¢è¿ä½¿ç”¨æŠ¥å‘Šç”Ÿæˆå™¨ï¼**\n\n');
    stream.markdown('æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ç”Ÿæˆå„ç§ç±»å‹çš„é¡¹ç›®åˆ†æå’Œç»Ÿè®¡æŠ¥å‘Šã€‚\n\n');

    stream.markdown('ğŸš€ **å¿«é€Ÿå¼€å§‹**:\n');
    stream.markdown('- è¾“å…¥ `é¡¹ç›®åˆ†æ` ç”Ÿæˆå®Œæ•´é¡¹ç›®æŠ¥å‘Š\n');
    stream.markdown('- è¾“å…¥ `c#` ç”ŸæˆC#ä»£ç è´¨é‡æŠ¥å‘Š\n');
    stream.markdown('- è¾“å…¥ `llmç»Ÿè®¡` æŸ¥çœ‹LLMä½¿ç”¨æƒ…å†µ\n');
    stream.markdown('- è¾“å…¥ `æ€§èƒ½æŠ¥å‘Š` æŸ¥çœ‹æ€§èƒ½ç›‘æ§æ•°æ®\n');
    stream.markdown('- è¾“å…¥ `å¸®åŠ©` è·å–è¯¦ç»†ä½¿ç”¨æŒ‡å—\n\n');

    stream.markdown('ğŸ’¡ **æç¤º**: æ‰€æœ‰æŠ¥å‘Šéƒ½ä¼šè‡ªåŠ¨ä¿å­˜ï¼Œæ–¹ä¾¿åç»­æŸ¥çœ‹å’Œåˆ†äº«ã€‚');
  }

  /**
   * ä»æç¤ºè¯ä¸­æå–æŠ¥å‘Šæ ¼å¼
   */
  private extractFormatFromPrompt(prompt: string): 'markdown' | 'json' | 'html' {
    if (prompt.includes('json')) return 'json';
    if (prompt.includes('html')) return 'html';
    return 'markdown'; // é»˜è®¤æ ¼å¼
  }

  /**
   * ä»æç¤ºè¯ä¸­æå–æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
   */
  private extractTimeRangeFromPrompt(prompt: string): number {
    // åŒ¹é…æ•°å­—+æ—¶é—´å•ä½çš„æ¨¡å¼
    const hourMatch = prompt.match(/(\d+)\s*[å°æ—¶æ—¶]/);
    if (hourMatch) {
      return parseInt(hourMatch[1]);
    }

    const dayMatch = prompt.match(/(\d+)\s*[å¤©æ—¥]/);
    if (dayMatch) {
      return parseInt(dayMatch[1]) * 24;
    }

    const weekMatch = prompt.match(/(\d+)\s*[å‘¨æ˜ŸæœŸ]/);
    if (weekMatch) {
      return parseInt(weekMatch[1]) * 24 * 7;
    }

    // é»˜è®¤24å°æ—¶
    return 24;
  }

  /**
   * ç”Ÿæˆæ™ºèƒ½å¸®åŠ©ä¿¡æ¯
   */
  protected generateHelpMessage(): string {
    return (
      `# ğŸ“Š æŠ¥å‘Šç”Ÿæˆå™¨ä½¿ç”¨æŒ‡å—\n\n` +
      `## ğŸ¯ ä¸»è¦åŠŸèƒ½\n\n` +
      `- **é¡¹ç›®åˆ†ææŠ¥å‘Š**: å…¨é¢åˆ†æé¡¹ç›®ç»“æ„ã€ä»£ç è´¨é‡å’Œæ½œåœ¨é—®é¢˜\n` +
      `- **C#ä»£ç æŠ¥å‘Š**: ä¸“é—¨é’ˆå¯¹C#é¡¹ç›®çš„ä»£ç è§„èŒƒæ£€æŸ¥\n` +
      `- **AIä½¿ç”¨æŠ¥å‘Š**: ç»Ÿè®¡å’Œåˆ†æAIæ¨¡å‹çš„ä½¿ç”¨æƒ…å†µ\n` +
      `- **æ€§èƒ½ç›‘æ§æŠ¥å‘Š**: é¡¹ç›®æ€§èƒ½æŒ‡æ ‡å’Œä¼˜åŒ–å»ºè®®\n\n` +
      `## ğŸ’¬ ä½¿ç”¨ç¤ºä¾‹\n\n` +
      `\`\`\`\n` +
      `@report ç”Ÿæˆé¡¹ç›®åˆ†ææŠ¥å‘Š\n` +
      `@report æ£€æŸ¥C#ä»£ç è§„èŒƒ\n` +
      `@report æ˜¾ç¤ºAIä½¿ç”¨ç»Ÿè®¡\n` +
      `@report ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š\n` +
      `\`\`\`\n\n` +
      `## ğŸ“‹ æŠ¥å‘Šæ ¼å¼\n\n` +
      `æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼š\n` +
      `- **Markdown**: é€‚åˆé˜…è¯»å’Œåˆ†äº«\n` +
      `- **JSON**: é€‚åˆç¨‹åºå¤„ç†\n` +
      `- **HTML**: é€‚åˆç½‘é¡µå±•ç¤º\n\n` +
      `ğŸ’¡ **æç¤º**: æ‚¨å¯ä»¥åœ¨è¯·æ±‚ä¸­æŒ‡å®šæ ¼å¼ï¼Œä¾‹å¦‚ "ç”ŸæˆJSONæ ¼å¼çš„é¡¹ç›®æŠ¥å‘Š"\n`
    );
  }
}
