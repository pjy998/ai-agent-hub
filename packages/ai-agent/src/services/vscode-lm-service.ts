/**
 * VS Code Language Model æœåŠ¡
 * ä½¿ç”¨VS Codeå†…ç½®çš„Language Model API (GitHub Copilot)
 * æä¾›ç»Ÿä¸€çš„AIæ™ºèƒ½åˆ†æèƒ½åŠ›
 */

import * as vscode from 'vscode';
import { outputManager } from '../utils/output-manager';

export interface LMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface LMResponse {
  success: boolean;
  content?: string;
  error?: string;
  model?: string;
}

export interface AnalysisContext {
  projectPath?: string;
  fileContent?: string;
  fileName?: string;
  language?: string;
  userIntent?: string;
  previousAnalysis?: string[];
}

/**
 * VS Code Language Model æœåŠ¡ç±»
 * ä½¿ç”¨GitHub Copilotçš„GPT-4.1æ¨¡å‹æä¾›æ™ºèƒ½åˆ†æ
 */
export class VSCodeLMService {
  private static instance: VSCodeLMService;
  private availableModels: vscode.LanguageModelChat[] = [];
  private preferredModel: vscode.LanguageModelChat | null = null;

  private constructor() {}

  public static getInstance(): VSCodeLMService {
    if (!VSCodeLMService.instance) {
      VSCodeLMService.instance = new VSCodeLMService();
    }
    return VSCodeLMService.instance;
  }

  /**
   * åˆå§‹åŒ–æœåŠ¡ï¼Œè·å–å¯ç”¨çš„è¯­è¨€æ¨¡å‹
   */
  public async initialize(): Promise<boolean> {
    try {
      if (!vscode.lm || !vscode.lm.selectChatModels) {
        outputManager.logWarning('VS Code Language Model API ä¸å¯ç”¨');
        return false;
      }

      // è·å–æ‰€æœ‰å¯ç”¨çš„èŠå¤©æ¨¡å‹
      this.availableModels = await vscode.lm.selectChatModels();

      if (this.availableModels.length === 0) {
        outputManager.logWarning('æœªæ‰¾åˆ°å¯ç”¨çš„è¯­è¨€æ¨¡å‹');
        return false;
      }

      // ä¼˜å…ˆé€‰æ‹©GPT-4æ¨¡å‹
      this.preferredModel =
        this.availableModels.find(
          model =>
            model.name.toLowerCase().includes('gpt-4') ||
            model.name.toLowerCase().includes('copilot')
        ) || this.availableModels[0];

      outputManager.logInfo(`å·²åˆå§‹åŒ–è¯­è¨€æ¨¡å‹: ${this.preferredModel.name}`);
      return true;
    } catch (error) {
      outputManager.logError('åˆå§‹åŒ–è¯­è¨€æ¨¡å‹å¤±è´¥:', error as Error);
      return false;
    }
  }

  /**
   * æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
   */
  public isAvailable(): boolean {
    return this.preferredModel !== null && vscode.lm !== undefined;
  }

  /**
   * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  public getAvailableModels(): string[] {
    return this.availableModels.map(model => model.name);
  }

  /**
   * å‘é€æ¶ˆæ¯åˆ°è¯­è¨€æ¨¡å‹
   */
  public async sendMessage(messages: LMMessage[], _context?: AnalysisContext): Promise<LMResponse> {
    if (!this.isAvailable()) {
      return {
        success: false,
        error: 'Language Model æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¹¶ç™»å½• GitHub Copilot',
      };
    }

    try {
      // è½¬æ¢æ¶ˆæ¯æ ¼å¼
      const chatMessages = messages.map(msg => {
        switch (msg.role) {
          case 'system':
            return vscode.LanguageModelChatMessage.User(msg.content);
          case 'user':
            return vscode.LanguageModelChatMessage.User(msg.content);
          case 'assistant':
            return vscode.LanguageModelChatMessage.Assistant(msg.content);
          default:
            return vscode.LanguageModelChatMessage.User(msg.content);
        }
      });

      // å‘é€è¯·æ±‚
      const request = await this.preferredModel!.sendRequest(
        chatMessages,
        {},
        new vscode.CancellationTokenSource().token
      );

      // æ”¶é›†å“åº”
      let content = '';
      for await (const fragment of request.text) {
        content += fragment;
      }

      return {
        success: true,
        content: content.trim(),
        model: this.preferredModel!.name,
      };
    } catch (error) {
      outputManager.logError('Language Model è¯·æ±‚å¤±è´¥:', error as Error);
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error),
      };
    }
  }

  /**
   * åˆ†æä»£ç 
   */
  public async analyzeCode(
    code: string,
    language: string,
    analysisType: 'quality' | 'security' | 'performance' | 'structure' | 'general' = 'general',
    context?: AnalysisContext
  ): Promise<LMResponse> {
    const systemPrompt = this.getAnalysisSystemPrompt(analysisType, language);
    const userPrompt = this.buildCodeAnalysisPrompt(code, language, analysisType, context);

    const messages: LMMessage[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    return await this.sendMessage(messages, context);
  }

  /**
   * å›ç­”é—®é¢˜
   */
  public async answerQuestion(question: string, context?: AnalysisContext): Promise<LMResponse> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”å„ç§ç¼–ç¨‹ç›¸å…³çš„é—®é¢˜ã€‚è¯·æä¾›å‡†ç¡®ã€å®ç”¨çš„å»ºè®®å’Œè§£å†³æ–¹æ¡ˆã€‚

å›ç­”è¦æ±‚ï¼š
1. å‡†ç¡®ç†è§£é—®é¢˜çš„æ ¸å¿ƒ
2. æä¾›æ¸…æ™°çš„è§£é‡Šå’Œæ­¥éª¤
3. åŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹ï¼ˆå¦‚é€‚ç”¨ï¼‰
4. è€ƒè™‘æœ€ä½³å®è·µå’Œå¸¸è§é™·é˜±
5. ä½¿ç”¨ä¸­æ–‡å›ç­”`;

    const contextInfo = context ? this.buildContextInfo(context) : '';
    const userPrompt = `${contextInfo}\n\né—®é¢˜: ${question}`;

    const messages: LMMessage[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    return await this.sendMessage(messages, context);
  }

  /**
   * è·å–åˆ†æç³»ç»Ÿæç¤º
   */
  private getAnalysisSystemPrompt(analysisType: string, language: string): string {
    const basePrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æä¸“å®¶ï¼Œä¸“é—¨åˆ†æ${language}ä»£ç ã€‚`;

    switch (analysisType) {
      case 'quality':
        return `${basePrompt}è¯·ä¸“æ³¨äºä»£ç è´¨é‡åˆ†æï¼ŒåŒ…æ‹¬å¯è¯»æ€§ã€å¯ç»´æŠ¤æ€§ã€ä»£ç è§„èŒƒç­‰æ–¹é¢ã€‚`;
      case 'security':
        return `${basePrompt}è¯·ä¸“æ³¨äºå®‰å…¨æ€§åˆ†æï¼Œè¯†åˆ«æ½œåœ¨çš„å®‰å…¨æ¼æ´å’Œé£é™©ã€‚`;
      case 'performance':
        return `${basePrompt}è¯·ä¸“æ³¨äºæ€§èƒ½åˆ†æï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼šã€‚`;
      case 'structure':
        return `${basePrompt}è¯·ä¸“æ³¨äºä»£ç ç»“æ„åˆ†æï¼Œè¯„ä¼°æ¶æ„è®¾è®¡å’Œç»„ç»‡æ–¹å¼ã€‚`;
      default:
        return `${basePrompt}è¯·è¿›è¡Œå…¨é¢çš„ä»£ç åˆ†æï¼ŒåŒ…æ‹¬è´¨é‡ã€å®‰å…¨æ€§ã€æ€§èƒ½å’Œç»“æ„ç­‰å„ä¸ªæ–¹é¢ã€‚`;
    }
  }

  /**
   * æ„å»ºä»£ç åˆ†ææç¤º
   */
  private buildCodeAnalysisPrompt(
    code: string,
    language: string,
    analysisType: string,
    context?: AnalysisContext
  ): string {
    const contextInfo = context ? this.buildContextInfo(context) : '';

    return `${contextInfo}

è¯·åˆ†æä»¥ä¸‹${language}ä»£ç ï¼š

\`\`\`${language}
${code}
\`\`\`

åˆ†æè¦æ±‚ï¼š
1. æä¾›è¯¦ç»†çš„åˆ†æç»“æœ
2. æŒ‡å‡ºå…·ä½“çš„é—®é¢˜å’Œæ”¹è¿›å»ºè®®
3. ç»™å‡ºä»£ç è´¨é‡è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
4. æä¾›å…·ä½“çš„ä¿®æ”¹å»ºè®®å’Œç¤ºä¾‹ä»£ç 
5. ä½¿ç”¨ä¸­æ–‡å›ç­”

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç»„ç»‡å›ç­”ï¼š
## ğŸ“Š åˆ†ææ¦‚è§ˆ
## ğŸ” è¯¦ç»†åˆ†æ
## âš ï¸ å‘ç°çš„é—®é¢˜
## ğŸ’¡ æ”¹è¿›å»ºè®®
## ğŸ“ ç¤ºä¾‹ä»£ç `;
  }

  /**
   * æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
   */
  private buildContextInfo(context: AnalysisContext): string {
    let contextInfo = '';

    if (context.projectPath) {
      contextInfo += `é¡¹ç›®è·¯å¾„: ${context.projectPath}\n`;
    }

    if (context.fileName) {
      contextInfo += `æ–‡ä»¶å: ${context.fileName}\n`;
    }

    if (context.language) {
      contextInfo += `ç¼–ç¨‹è¯­è¨€: ${context.language}\n`;
    }

    if (context.userIntent) {
      contextInfo += `ç”¨æˆ·æ„å›¾: ${context.userIntent}\n`;
    }

    if (context.previousAnalysis && context.previousAnalysis.length > 0) {
      contextInfo += `\nå†å²åˆ†æ:\n${context.previousAnalysis.slice(-3).join('\n')}\n`;
    }

    return contextInfo;
  }

  /**
   * è·å–é…ç½®çŠ¶æ€
   */
  public getConfigurationStatus(): {
    configured: boolean;
    model: string;
    available: boolean;
    modelCount: number;
  } {
    return {
      configured: this.isAvailable(),
      model: this.preferredModel?.name || 'N/A',
      available: vscode.lm !== undefined,
      modelCount: this.availableModels.length,
    };
  }

  /**
   * é‡ç½®æœåŠ¡
   */
  public reset(): void {
    this.availableModels = [];
    this.preferredModel = null;
  }
}
